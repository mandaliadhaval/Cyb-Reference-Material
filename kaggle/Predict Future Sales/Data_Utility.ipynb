{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path ='data/' ):\n",
    "\titem_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "\ttest= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "\tsub = test.copy()\n",
    "\tsub['item_cnt_month'] = item_cnt_month\n",
    "\tsub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "\tsub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "\treturn sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xgb_feature_importances(importances):\n",
    "\tsorted_columns=[]\n",
    "\tsorted_values=[]\n",
    "\tfor key in sorted(importances, key=importances.get,reverse=False):\n",
    "\t\tsorted_columns.append(key)\n",
    "\t\tsorted_values.append(importances[key])\n",
    "\n",
    "\tlength = len(importances)\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tplt.title('Feature Importances')\n",
    "\tplt.barh(range(length),sorted_values[:length],color='lightblue',align='center',height=0.8)\n",
    "\tplt.yticks(range(length),sorted_columns[:length])\n",
    "\tplt.ylim([-1,length])\n",
    "\tplt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "\t'''\n",
    "\tChanges column types in the dataframe: \n",
    "\t\t\n",
    "\t\t`float64` type to `float32`\n",
    "\t\t`int64`   type to `int32`\n",
    "\t'''\n",
    "\n",
    "\t# Select columns to downcast\n",
    "\tfloat_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "\tint_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "\n",
    "\t# Downcast\n",
    "\tdf[float_cols] = df[float_cols].astype(np.float32)\n",
    "\tdf[int_cols]   = df[int_cols].astype(np.int32)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_idxs(df,start,end):\n",
    "\tresult=[]\n",
    "\tfor i in range(start,end+1):\n",
    "\t\tdates = df.date_block_num\n",
    "\t\ttrain_idx = np.array(df.loc[dates <i].index)\n",
    "\t\tval_idx = np.array(df.loc[dates == i].index)\n",
    "\t\tresult.append((train_idx,val_idx))\n",
    "\treturn np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df,end,clip=20):\n",
    "\t# don't drop date_block_num\n",
    "\tdf = df.loc[df.date_block_num <= end]\n",
    "\tcols_to_drop=['target','item_name'] + df.columns.values[6:12].tolist()\n",
    "\ty = np.clip(df.target.values,0,clip)\n",
    "\tX = df.drop(cols_to_drop,axis=1)\n",
    "\treturn X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(truth,pred):\n",
    "\treturn sqrt(mean_squared_error(truth,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(data_path,filename):\n",
    "\tall_data = pd.read_pickle(data_path + filename)\n",
    "\tall_data = downcast_dtypes(all_data)\n",
    "\tall_data = all_data.reset_index().drop('index',axis=1)\n",
    "\treturn all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_sample(data_path,filename,ratio=.2,seed=42):\n",
    "\tall_data = get_all_data(data_path,filename)\n",
    "\tn_sample = int(all_data.shape[0] * ratio)\n",
    "\tnp.random.seed(seed)\n",
    "\tidx_sample = np.random.choice(all_data.shape[0], n_sample, replace=False)\n",
    "\tall_data_sample = all_data.iloc[idx_sample].copy()\n",
    "\tall_data_sample = all_data_sample.reset_index().drop('index',axis=1)\n",
    "\treturn all_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(X,y,val_block):\n",
    "\tif val_block>33:\n",
    "\t\traise ValueError('Maximum date_block_n is 33')\n",
    "\tX_train  = X[X.date_block_num<val_block].copy()\n",
    "\tX_val = X[X.date_block_num==val_block].copy()\n",
    "\ty_train = y[X_train.index.tolist()].copy()\n",
    "\ty_val = y[X_val.index.tolist()].copy()\n",
    "\tX_train.drop('date_block_num',axis=1,inplace=True)\n",
    "\tX_val.drop('date_block_num',axis=1,inplace=True)\n",
    "\treturn X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_cv(clf_name,X,y,params,cv,loss_metric,early_stopping_round=100,get_oof=False,extra_rounds=1):\n",
    "\t'''\n",
    "\tDoing XGBoost and LightGBM CV for time series.\n",
    "\tclf_name: 'xgb' or 'lgb'\n",
    "\tcv: [(train idx time 1,val idx time 1),( train idx time 2, val idx time 2), ...]\n",
    "\t'''\n",
    "\tprint(\"Training with params: \")\n",
    "\tprint(params)\n",
    "\n",
    "\toof_train = np.zeros([0,])\n",
    "\tcv_losses=[]\n",
    "\tcv_iteration=[]\n",
    "\n",
    "\tfor (train_idx,val_idx) in cv:\n",
    "\t\tcv_train = X.iloc[train_idx]\n",
    "\t\tcv_val = X.iloc[val_idx]\n",
    "\t\tcv_y_train = y[train_idx]\n",
    "\t\tcv_y_val = y[val_idx]\n",
    "\n",
    "\t\ttrain_pred=None\n",
    "\t\tval_pred=None\n",
    "\t\tbest_nround=0\n",
    "\t\tif clf_name == 'lgb':\n",
    "            \n",
    "\t\t\tlgb_model = lgb.train(params, lgb.Dataset(cv_train, label=cv_y_train), 2000, \n",
    "\t\t\t\t      lgb.Dataset(cv_val, label=cv_y_val), verbose_eval=False, \n",
    "\t\t\t\t      early_stopping_rounds=early_stopping_round)\n",
    "\t\t\tbest_nround=lgb_model.best_iteration\n",
    "\t\t\ttrain_pred = lgb_model.predict(cv_train,best_nround)\n",
    "\t\t\tval_pred = lgb_model.predict(cv_val,best_nround+extra_rounds)\n",
    "        \n",
    "\n",
    "\t\telif clf_name == 'xgb':\n",
    "\t\t\tdtrain = xgb.DMatrix(cv_train,cv_y_train)\n",
    "\t\t\tdval = xgb.DMatrix(cv_val,cv_y_val)\n",
    "\t\t\twatchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "\t\t\txgb_model = xgb.train(params, dtrain, 2000, watchlist,\n",
    "\t\t\t\t      verbose_eval=False, \n",
    "\t\t\t\t      early_stopping_rounds=early_stopping_round)\n",
    "\t\t\tbest_nround=xgb_model.best_ntree_limit\n",
    "\t\t\ttrain_pred = xgb_model.predict(dtrain,ntree_limit=best_nround)\n",
    "\t\t\tval_pred = xgb_model.predict(dval,ntree_limit=best_nround+extra_rounds)\n",
    "\n",
    "\t\t\txgb_model.__del__()\n",
    "\t\telse:\n",
    "\t\t\treturn None\n",
    "        \n",
    "        #  oof_train[dbn_level2==current_bn] = val_pred\n",
    "\t\tif get_oof:\n",
    "\t\t\toof_train = np.append(oof_train,val_pred)\n",
    "    \n",
    "\t\tval_loss = loss_metric(cv_y_val,val_pred)\n",
    "\t\ttrain_loss = loss_metric(cv_y_train,train_pred)\n",
    "\t\tprint('Train RMSE: {}. Val RMSE: {}'.format(train_loss,val_loss))\n",
    "\t\tprint('Best iteration: {}'.format(best_nround))\n",
    "\t\tcv_losses.append(val_loss)\n",
    "\t\tcv_iteration.append(best_nround)\n",
    "        \n",
    "\tprint('n validation fold results: {}'.format(cv_losses))\n",
    "\n",
    "\tprint('Average iterations: {}'.format(int(np.mean(cv_iteration))))\n",
    "\tprint(\"Mean Cross Validation RMSE: {}\\n\".format(np.mean(cv_losses)))\n",
    "\n",
    "\treturn (oof_train,cv_losses) if get_oof else cv_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
